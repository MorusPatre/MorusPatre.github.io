import csv
import json
import os
import re
import unicodedata
import pandas as pd

# --- HELPER FUNCTIONS ---
def simplify_text_for_search(text):
    if not text: return ""
    nfkd_form = unicodedata.normalize('NFD', text)
    return "".join([c for c in nfkd_form if not unicodedata.combining(c)])

def to_kebab_case(text):
    s1 = re.sub(r'(.)([A-Z][a-z]+)', r'\1-\2', text)
    return re.sub(r'([a-z0-9])([A-Z])', r'\1-\2', s1).replace(' ', '-').lower()

# --- MAIN SCRIPT LOGIC ---
try:
    csv_filename = 'mdls_metadata_formatted.csv'
    with open(csv_filename, mode='r', newline='', encoding='utf-8') as infile:
        reader = csv.DictReader(infile)
        all_rows = list(reader)

    all_images_data = []
    cdn_base_url = "https://cdn.mouseia.com"

    for row in all_rows:
        relative_path = row.get('Relative File path')
        if not relative_path:
            continue

        actual_filename = os.path.basename(relative_path)
        metadata_filename = row.get('File name', '')

        # --- MODIFICATION START: Read from new Cast/Crew columns ---
        cast_raw = row.get('Cast', '') if pd.notna(row.get('Cast')) else ''
        crew_raw = row.get('Crew', '') if pd.notna(row.get('Crew')) else ''
        cast_and_crew_combined_raw = row.get('Cast & Crew', '') if pd.notna(row.get('Cast & Crew')) else ''
        characters_raw = row.get('Characters', '') if pd.notna(row.get('Characters')) else ''

        people_display = ""
        # Determine the final list of people based on the new logic
        if cast_and_crew_combined_raw:
            people_display = cast_and_crew_combined_raw
        else:
            people_parts = [p for p in [cast_raw, crew_raw] if p]
            people_display = ", ".join(people_parts)
        
        characters_display = ", ".join([char.strip() for char in characters_raw.split(',') if char.strip()])
        # --- MODIFICATION END ---
        
        season_str, episode_str = row.get('Season'), row.get('Episode')
        
        # Generate search terms
        search_terms_set = set()
        name_without_ext, _ = os.path.splitext(actual_filename)
        search_terms_set.add(simplify_text_for_search(name_without_ext.lower()))
        search_terms_set.add(simplify_text_for_search(actual_filename.lower()))
        
        if season_str:
            search_terms_set.add(f"s{season_str}")
            search_terms_set.add(f"season {season_str}")

        if episode_str:
            search_terms_set.add(f"e{episode_str}")
            search_terms_set.add(f"episode {episode_str}")

        if season_str and episode_str:
            search_terms_set.add(f"s{season_str}e{episode_str}")

        if people_display: search_terms_set.add(simplify_text_for_search(people_display.lower()))
        if characters_display: search_terms_set.add(simplify_text_for_search(characters_display.lower()))
        search_attr = " ".join(sorted(list(search_terms_set)))
        
        final_src_path = f"the-witcher/{actual_filename}"
        thumbnail_path = f"the-witcher/thumbnail/{name_without_ext}.webp"

        image_data = {}
        image_data["src"] = f"{cdn_base_url}/{final_src_path}"
        image_data["thumbnail"] = f"{cdn_base_url}/{thumbnail_path}"
        image_data["filename"] = metadata_filename
        image_data["alt"] = f"Characters: {characters_display} | Cast: {people_display}"
        image_data["search"] = search_attr

        # --- MODIFICATION START: Add specific cast/crew keys to JSON ---
        if cast_and_crew_combined_raw:
            image_data['castAndCrew'] = cast_and_crew_combined_raw
        else:
            if cast_raw:
                image_data['cast'] = cast_raw
            if crew_raw:
                image_data['crew'] = crew_raw

        if characters_display:
            image_data['characters'] = characters_display
        # --- MODIFICATION END ---

        processed_or_skipped_keys = {
            'Relative File path', 'File name', 'Actors', 'Cast', 'Crew', 'Cast & Crew', 'Characters', 'Season', 'Episode'
        }

        # Add remaining metadata from CSV
        csv_headers = reader.fieldnames
        for col_header in csv_headers:
            if col_header in processed_or_skipped_keys: continue
            col_value = row.get(col_header)
            if pd.isna(col_value) or col_value == '': continue
            key_parts = to_kebab_case(col_header).split('-')
            camel_case_key = key_parts[0] + ''.join(x.title() for x in key_parts[1:])
            image_data[camel_case_key] = col_value

        # Add Season and Episode if they exist
        if season_str and season_str.isdigit(): image_data['season'] = int(season_str)
        if episode_str and episode_str.isdigit(): image_data['episode'] = int(episode_str)

        all_images_data.append(image_data)

    with open('gallery-data.json', 'w', encoding='utf-8') as f:
        json.dump(all_images_data, f, ensure_ascii=False, indent=2)
    
    print("âœ… Successfully generated gallery-data.json with specific cast, crew, and castAndCrew keys.")

except FileNotFoundError:
    print(f"--> ERROR: '{csv_filename}' not found. Please make sure the file is in the same directory.")
except Exception as e:
    print(f"An error occurred: {e}")
